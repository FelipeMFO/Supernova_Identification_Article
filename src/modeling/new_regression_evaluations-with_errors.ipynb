{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/felipe/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle as pk\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/processed/df_20features_redshift.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desg</th>\n",
       "      <th>desi</th>\n",
       "      <th>desr</th>\n",
       "      <th>desz</th>\n",
       "      <th>Xaxis</th>\n",
       "      <th>desg_GP</th>\n",
       "      <th>desi_GP</th>\n",
       "      <th>desr_GP</th>\n",
       "      <th>desz_GP</th>\n",
       "      <th>wavelets</th>\n",
       "      <th>...</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>type</th>\n",
       "      <th>type_bool</th>\n",
       "      <th>REDSHIFT_SPEC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SN100023</th>\n",
       "      <td>[[6.984000000004016, 5.679, 6.387], [7.9920000...</td>\n",
       "      <td>[[7.00800000000163, 4.698, 7.145], [8.02300000...</td>\n",
       "      <td>[[0.0, 16.04, 17.59], [6.992000000005646, 19.8...</td>\n",
       "      <td>[[4.121000000006461, 18.01, 3.601], [7.0230000...</td>\n",
       "      <td>[0.0, 1.3437474747475018, 2.6874949494950036, ...</td>\n",
       "      <td>([2.7042034170117253, 2.704203379882798, 2.704...</td>\n",
       "      <td>([9.210984520892023, 9.176410057411523, 9.1395...</td>\n",
       "      <td>([18.95157959234684, 18.542994851548404, 18.12...</td>\n",
       "      <td>([11.511496784869301, 11.466555748878534, 11.4...</td>\n",
       "      <td>[5.408305555798485, 5.408350230206628, 5.40838...</td>\n",
       "      <td>...</td>\n",
       "      <td>47.475268</td>\n",
       "      <td>22.339358</td>\n",
       "      <td>-8.555147</td>\n",
       "      <td>-20.272573</td>\n",
       "      <td>9.800754</td>\n",
       "      <td>-27.230832</td>\n",
       "      <td>-3.424349</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.79264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN100085</th>\n",
       "      <td>[[0.0, 14.24, 18.69], [0.046999999998661224, 1...</td>\n",
       "      <td>[[9.245999999999185, 2.122, 2.955], [17.238000...</td>\n",
       "      <td>[[0.008000000001629815, 0.4534, 9.048], [23.03...</td>\n",
       "      <td>[[0.024000000004889444, 8.451, 7.696], [10.168...</td>\n",
       "      <td>[0.0, 1.2024545454545972, 2.4049090909091944, ...</td>\n",
       "      <td>([3.716529330659685, 3.5625686823335636, 3.356...</td>\n",
       "      <td>([0.22260948197979502, 0.3996793089433659, 0.5...</td>\n",
       "      <td>([0.013168490497364349, -0.0898721956550923, -...</td>\n",
       "      <td>([6.843383353229822, 6.685880257682825, 6.5058...</td>\n",
       "      <td>[3.8346626513696225, 5.304183229080858, 6.3480...</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.987002</td>\n",
       "      <td>-29.304439</td>\n",
       "      <td>24.379562</td>\n",
       "      <td>44.752307</td>\n",
       "      <td>-17.355709</td>\n",
       "      <td>6.271127</td>\n",
       "      <td>52.140213</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.65600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN100114</th>\n",
       "      <td>[[0.2809999999954016, 6.707, 10.62], [5.260999...</td>\n",
       "      <td>[[0.0, 5.127, 5.467], [5.9799999999959255, 4.5...</td>\n",
       "      <td>[[5.277000000001863, 6.017, 3.299], [6.2609999...</td>\n",
       "      <td>[[4.987999999997555, 1.516, 8.327], [6.9879999...</td>\n",
       "      <td>[0.0, 1.1410505050505044, 2.282101010101009, 3...</td>\n",
       "      <td>([6.30179553883895, 6.163399755424116, 5.90410...</td>\n",
       "      <td>([4.501175940761371, 4.884878693958981, 5.2329...</td>\n",
       "      <td>([6.970237496131654, 6.258842555550748, 5.6350...</td>\n",
       "      <td>([12.16350518315572, 10.810842707072254, 9.097...</td>\n",
       "      <td>[18.458977393379286, 16.046616727416012, 13.67...</td>\n",
       "      <td>...</td>\n",
       "      <td>126.883803</td>\n",
       "      <td>-79.046296</td>\n",
       "      <td>323.571740</td>\n",
       "      <td>60.588944</td>\n",
       "      <td>-62.613276</td>\n",
       "      <td>-177.089830</td>\n",
       "      <td>71.567560</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.20095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN100177</th>\n",
       "      <td>[[6.980000000003201, 1.914, 2.033], [14.980000...</td>\n",
       "      <td>[[8.042999999997846, 0.01975, 3.008], [19.9800...</td>\n",
       "      <td>[[6.995999999999185, 0.4865, 1.444], [15.00400...</td>\n",
       "      <td>[[0.0, 0.9217, 3.049], [21.995999999999185, 5....</td>\n",
       "      <td>[0.0, 0.8466262626262514, 1.6932525252525028, ...</td>\n",
       "      <td>([1.139219526385169, 1.2164271451388768, 1.295...</td>\n",
       "      <td>([-0.7877409693040072, -0.7722841243756449, -0...</td>\n",
       "      <td>([-0.6894051675222933, -0.6382299020654087, -0...</td>\n",
       "      <td>([1.4328523933541817, 1.612303136114413, 1.794...</td>\n",
       "      <td>[8.772762795164342, 5.92446213264885, 3.746806...</td>\n",
       "      <td>...</td>\n",
       "      <td>33.713789</td>\n",
       "      <td>-29.794074</td>\n",
       "      <td>14.294094</td>\n",
       "      <td>37.541937</td>\n",
       "      <td>-8.246827</td>\n",
       "      <td>-35.067612</td>\n",
       "      <td>-3.614580</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.46557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN899766</th>\n",
       "      <td>[[6.984000000004016, 2.619, 6.376], [21.973000...</td>\n",
       "      <td>[[0.012000000002444722, 48.86, 49.95], [8.0230...</td>\n",
       "      <td>[[0.0, 19.65, 17.59], [6.992000000005646, 5.34...</td>\n",
       "      <td>[[4.121000000006461, 1.07, 3.581], [7.02300000...</td>\n",
       "      <td>[0.0, 1.474707070707136, 2.949414141414272, 4....</td>\n",
       "      <td>([3.1774853444736557, 3.1774855699966595, 3.17...</td>\n",
       "      <td>([6.273860823260804, 6.090278522008031, 5.9044...</td>\n",
       "      <td>([8.309936227222874, 8.154384056314196, 7.9766...</td>\n",
       "      <td>([1.0347047221511048, 1.209742608349444, 1.388...</td>\n",
       "      <td>[6.3549756079875195, 6.354973557479621, 6.3549...</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.871439</td>\n",
       "      <td>-85.058740</td>\n",
       "      <td>23.367325</td>\n",
       "      <td>86.632538</td>\n",
       "      <td>21.008687</td>\n",
       "      <td>-14.510971</td>\n",
       "      <td>64.077706</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.84069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN899772</th>\n",
       "      <td>[[0.0, 8.811, 25.57], [5.875, 1.341, 4.764], [...</td>\n",
       "      <td>[[0.8550000000032014, 10.26, 30.95], [21.81600...</td>\n",
       "      <td>[[0.015000000006693881, 7.061, 4.154], [32.820...</td>\n",
       "      <td>[[19.851000000002387, 3.151, 4.938], [27.85100...</td>\n",
       "      <td>[0.0, 1.6130000000000542, 3.2260000000001083, ...</td>\n",
       "      <td>([3.375523849152177, 2.9073715158475206, 2.313...</td>\n",
       "      <td>([5.9244796371948585, 5.563986512566748, 5.176...</td>\n",
       "      <td>([6.3162013263673575, 5.386246481590906, 4.336...</td>\n",
       "      <td>([11.990492759478087, 11.552298169626269, 11.0...</td>\n",
       "      <td>[3.341657653722518, 4.5430537588317765, 5.0680...</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.440696</td>\n",
       "      <td>55.496760</td>\n",
       "      <td>-63.973373</td>\n",
       "      <td>-119.170704</td>\n",
       "      <td>23.982747</td>\n",
       "      <td>-77.691256</td>\n",
       "      <td>-40.448599</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.47005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN899777</th>\n",
       "      <td>[[0.0, 3.066, 3.91], [0.8009999999994761, 15.1...</td>\n",
       "      <td>[[13.788999999997031, 3.201, 4.192], [14.80099...</td>\n",
       "      <td>[[0.008000000001629815, 2.275, 5.58], [0.81699...</td>\n",
       "      <td>[[0.8600000000005821, 11.96, 5.06], [6.8359999...</td>\n",
       "      <td>[0.0, 1.311363636363607, 2.622727272727214, 3....</td>\n",
       "      <td>([1.035409786279157, 1.0654355765245267, 1.097...</td>\n",
       "      <td>([5.5105922415789195, 5.384141464291133, 5.253...</td>\n",
       "      <td>([2.4760379841089275, 2.5448649370640624, 2.58...</td>\n",
       "      <td>([3.0547576395107967, 3.133081740221371, 3.217...</td>\n",
       "      <td>[4.908064260185052, 3.6456116683397255, 2.6941...</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.120681</td>\n",
       "      <td>-38.258819</td>\n",
       "      <td>5.569152</td>\n",
       "      <td>143.246575</td>\n",
       "      <td>59.833476</td>\n",
       "      <td>-6.080932</td>\n",
       "      <td>92.213653</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.96836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN899894</th>\n",
       "      <td>[[4.946000000003551, 0.4706, 2.636], [12.84800...</td>\n",
       "      <td>[[20.89100000000326, 3.519, 3.209], [28.899000...</td>\n",
       "      <td>[[12.864000000001397, 0.06272, 2.322], [28.879...</td>\n",
       "      <td>[[0.0, 0.5017, 2.964], [12.902999999998428, 1....</td>\n",
       "      <td>[0.0, 1.6342020202020209, 3.2684040404040418, ...</td>\n",
       "      <td>([0.5826453395648821, 0.6122115256870917, 0.64...</td>\n",
       "      <td>([-2.1020468565115067, -1.8163280187884538, -1...</td>\n",
       "      <td>([5.22669702405458, 5.045645124683354, 4.66633...</td>\n",
       "      <td>([-0.8891914351648893, -0.6117691393582163, -0...</td>\n",
       "      <td>[3.080265355416106, 2.2195112229080918, 1.5941...</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.953367</td>\n",
       "      <td>-21.693920</td>\n",
       "      <td>13.137965</td>\n",
       "      <td>139.137226</td>\n",
       "      <td>22.776597</td>\n",
       "      <td>30.205303</td>\n",
       "      <td>75.482211</td>\n",
       "      <td>II</td>\n",
       "      <td>False</td>\n",
       "      <td>0.98557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18916 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       desg  \\\n",
       "ID                                                            \n",
       "SN100023  [[6.984000000004016, 5.679, 6.387], [7.9920000...   \n",
       "SN100085  [[0.0, 14.24, 18.69], [0.046999999998661224, 1...   \n",
       "SN100114  [[0.2809999999954016, 6.707, 10.62], [5.260999...   \n",
       "SN100177  [[6.980000000003201, 1.914, 2.033], [14.980000...   \n",
       "...                                                     ...   \n",
       "SN899766  [[6.984000000004016, 2.619, 6.376], [21.973000...   \n",
       "SN899772  [[0.0, 8.811, 25.57], [5.875, 1.341, 4.764], [...   \n",
       "SN899777  [[0.0, 3.066, 3.91], [0.8009999999994761, 15.1...   \n",
       "SN899894  [[4.946000000003551, 0.4706, 2.636], [12.84800...   \n",
       "\n",
       "                                                       desi  \\\n",
       "ID                                                            \n",
       "SN100023  [[7.00800000000163, 4.698, 7.145], [8.02300000...   \n",
       "SN100085  [[9.245999999999185, 2.122, 2.955], [17.238000...   \n",
       "SN100114  [[0.0, 5.127, 5.467], [5.9799999999959255, 4.5...   \n",
       "SN100177  [[8.042999999997846, 0.01975, 3.008], [19.9800...   \n",
       "...                                                     ...   \n",
       "SN899766  [[0.012000000002444722, 48.86, 49.95], [8.0230...   \n",
       "SN899772  [[0.8550000000032014, 10.26, 30.95], [21.81600...   \n",
       "SN899777  [[13.788999999997031, 3.201, 4.192], [14.80099...   \n",
       "SN899894  [[20.89100000000326, 3.519, 3.209], [28.899000...   \n",
       "\n",
       "                                                       desr  \\\n",
       "ID                                                            \n",
       "SN100023  [[0.0, 16.04, 17.59], [6.992000000005646, 19.8...   \n",
       "SN100085  [[0.008000000001629815, 0.4534, 9.048], [23.03...   \n",
       "SN100114  [[5.277000000001863, 6.017, 3.299], [6.2609999...   \n",
       "SN100177  [[6.995999999999185, 0.4865, 1.444], [15.00400...   \n",
       "...                                                     ...   \n",
       "SN899766  [[0.0, 19.65, 17.59], [6.992000000005646, 5.34...   \n",
       "SN899772  [[0.015000000006693881, 7.061, 4.154], [32.820...   \n",
       "SN899777  [[0.008000000001629815, 2.275, 5.58], [0.81699...   \n",
       "SN899894  [[12.864000000001397, 0.06272, 2.322], [28.879...   \n",
       "\n",
       "                                                       desz  \\\n",
       "ID                                                            \n",
       "SN100023  [[4.121000000006461, 18.01, 3.601], [7.0230000...   \n",
       "SN100085  [[0.024000000004889444, 8.451, 7.696], [10.168...   \n",
       "SN100114  [[4.987999999997555, 1.516, 8.327], [6.9879999...   \n",
       "SN100177  [[0.0, 0.9217, 3.049], [21.995999999999185, 5....   \n",
       "...                                                     ...   \n",
       "SN899766  [[4.121000000006461, 1.07, 3.581], [7.02300000...   \n",
       "SN899772  [[19.851000000002387, 3.151, 4.938], [27.85100...   \n",
       "SN899777  [[0.8600000000005821, 11.96, 5.06], [6.8359999...   \n",
       "SN899894  [[0.0, 0.5017, 2.964], [12.902999999998428, 1....   \n",
       "\n",
       "                                                      Xaxis  \\\n",
       "ID                                                            \n",
       "SN100023  [0.0, 1.3437474747475018, 2.6874949494950036, ...   \n",
       "SN100085  [0.0, 1.2024545454545972, 2.4049090909091944, ...   \n",
       "SN100114  [0.0, 1.1410505050505044, 2.282101010101009, 3...   \n",
       "SN100177  [0.0, 0.8466262626262514, 1.6932525252525028, ...   \n",
       "...                                                     ...   \n",
       "SN899766  [0.0, 1.474707070707136, 2.949414141414272, 4....   \n",
       "SN899772  [0.0, 1.6130000000000542, 3.2260000000001083, ...   \n",
       "SN899777  [0.0, 1.311363636363607, 2.622727272727214, 3....   \n",
       "SN899894  [0.0, 1.6342020202020209, 3.2684040404040418, ...   \n",
       "\n",
       "                                                    desg_GP  \\\n",
       "ID                                                            \n",
       "SN100023  ([2.7042034170117253, 2.704203379882798, 2.704...   \n",
       "SN100085  ([3.716529330659685, 3.5625686823335636, 3.356...   \n",
       "SN100114  ([6.30179553883895, 6.163399755424116, 5.90410...   \n",
       "SN100177  ([1.139219526385169, 1.2164271451388768, 1.295...   \n",
       "...                                                     ...   \n",
       "SN899766  ([3.1774853444736557, 3.1774855699966595, 3.17...   \n",
       "SN899772  ([3.375523849152177, 2.9073715158475206, 2.313...   \n",
       "SN899777  ([1.035409786279157, 1.0654355765245267, 1.097...   \n",
       "SN899894  ([0.5826453395648821, 0.6122115256870917, 0.64...   \n",
       "\n",
       "                                                    desi_GP  \\\n",
       "ID                                                            \n",
       "SN100023  ([9.210984520892023, 9.176410057411523, 9.1395...   \n",
       "SN100085  ([0.22260948197979502, 0.3996793089433659, 0.5...   \n",
       "SN100114  ([4.501175940761371, 4.884878693958981, 5.2329...   \n",
       "SN100177  ([-0.7877409693040072, -0.7722841243756449, -0...   \n",
       "...                                                     ...   \n",
       "SN899766  ([6.273860823260804, 6.090278522008031, 5.9044...   \n",
       "SN899772  ([5.9244796371948585, 5.563986512566748, 5.176...   \n",
       "SN899777  ([5.5105922415789195, 5.384141464291133, 5.253...   \n",
       "SN899894  ([-2.1020468565115067, -1.8163280187884538, -1...   \n",
       "\n",
       "                                                    desr_GP  \\\n",
       "ID                                                            \n",
       "SN100023  ([18.95157959234684, 18.542994851548404, 18.12...   \n",
       "SN100085  ([0.013168490497364349, -0.0898721956550923, -...   \n",
       "SN100114  ([6.970237496131654, 6.258842555550748, 5.6350...   \n",
       "SN100177  ([-0.6894051675222933, -0.6382299020654087, -0...   \n",
       "...                                                     ...   \n",
       "SN899766  ([8.309936227222874, 8.154384056314196, 7.9766...   \n",
       "SN899772  ([6.3162013263673575, 5.386246481590906, 4.336...   \n",
       "SN899777  ([2.4760379841089275, 2.5448649370640624, 2.58...   \n",
       "SN899894  ([5.22669702405458, 5.045645124683354, 4.66633...   \n",
       "\n",
       "                                                    desz_GP  \\\n",
       "ID                                                            \n",
       "SN100023  ([11.511496784869301, 11.466555748878534, 11.4...   \n",
       "SN100085  ([6.843383353229822, 6.685880257682825, 6.5058...   \n",
       "SN100114  ([12.16350518315572, 10.810842707072254, 9.097...   \n",
       "SN100177  ([1.4328523933541817, 1.612303136114413, 1.794...   \n",
       "...                                                     ...   \n",
       "SN899766  ([1.0347047221511048, 1.209742608349444, 1.388...   \n",
       "SN899772  ([11.990492759478087, 11.552298169626269, 11.0...   \n",
       "SN899777  ([3.0547576395107967, 3.133081740221371, 3.217...   \n",
       "SN899894  ([-0.8891914351648893, -0.6117691393582163, -0...   \n",
       "\n",
       "                                                   wavelets  ...         f14  \\\n",
       "ID                                                           ...               \n",
       "SN100023  [5.408305555798485, 5.408350230206628, 5.40838...  ...   47.475268   \n",
       "SN100085  [3.8346626513696225, 5.304183229080858, 6.3480...  ...  -11.987002   \n",
       "SN100114  [18.458977393379286, 16.046616727416012, 13.67...  ...  126.883803   \n",
       "SN100177  [8.772762795164342, 5.92446213264885, 3.746806...  ...   33.713789   \n",
       "...                                                     ...  ...         ...   \n",
       "SN899766  [6.3549756079875195, 6.354973557479621, 6.3549...  ...  -22.871439   \n",
       "SN899772  [3.341657653722518, 4.5430537588317765, 5.0680...  ...  -66.440696   \n",
       "SN899777  [4.908064260185052, 3.6456116683397255, 2.6941...  ...  -21.120681   \n",
       "SN899894  [3.080265355416106, 2.2195112229080918, 1.5941...  ...  -20.953367   \n",
       "\n",
       "                f15         f16         f17        f18         f19        f20  \\\n",
       "ID                                                                              \n",
       "SN100023  22.339358   -8.555147  -20.272573   9.800754  -27.230832  -3.424349   \n",
       "SN100085 -29.304439   24.379562   44.752307 -17.355709    6.271127  52.140213   \n",
       "SN100114 -79.046296  323.571740   60.588944 -62.613276 -177.089830  71.567560   \n",
       "SN100177 -29.794074   14.294094   37.541937  -8.246827  -35.067612  -3.614580   \n",
       "...             ...         ...         ...        ...         ...        ...   \n",
       "SN899766 -85.058740   23.367325   86.632538  21.008687  -14.510971  64.077706   \n",
       "SN899772  55.496760  -63.973373 -119.170704  23.982747  -77.691256 -40.448599   \n",
       "SN899777 -38.258819    5.569152  143.246575  59.833476   -6.080932  92.213653   \n",
       "SN899894 -21.693920   13.137965  139.137226  22.776597   30.205303  75.482211   \n",
       "\n",
       "          type  type_bool  REDSHIFT_SPEC  \n",
       "ID                                        \n",
       "SN100023    II      False        0.79264  \n",
       "SN100085    II      False        0.65600  \n",
       "SN100114    II      False        0.20095  \n",
       "SN100177    II      False        0.46557  \n",
       "...        ...        ...            ...  \n",
       "SN899766    II      False        0.84069  \n",
       "SN899772    II      False        0.47005  \n",
       "SN899777    II      False        0.96836  \n",
       "SN899894    II      False        0.98557  \n",
       "\n",
       "[18916 rows x 33 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_true_test: [ 1113  1114  1115 ... 18913 18914 18915] X_to_train: [   0    1    2 ... 1110 1111 1112]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [1113 1114 1115 ... 2223 2224 2225]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [2226 2227 2228 ... 3336 3337 3338]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [3339 3340 3341 ... 4449 4450 4451]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [4452 4453 4454 ... 5562 5563 5564]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [5565 5566 5567 ... 6675 6676 6677]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [6678 6679 6680 ... 7788 7789 7790]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [7791 7792 7793 ... 8901 8902 8903]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [ 8904  8905  8906 ... 10014 10015 10016]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [10017 10018 10019 ... 11127 11128 11129]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [11130 11131 11132 ... 12240 12241 12242]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [12243 12244 12245 ... 13353 13354 13355]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [13356 13357 13358 ... 14465 14466 14467]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [14468 14469 14470 ... 15577 15578 15579]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [15580 15581 15582 ... 16689 16690 16691]\n",
      "X_true_test: [    0     1     2 ... 18913 18914 18915] X_to_train: [16692 16693 16694 ... 17801 17802 17803]\n",
      "X_true_test: [    0     1     2 ... 17801 17802 17803] X_to_train: [17804 17805 17806 ... 18913 18914 18915]\n"
     ]
    }
   ],
   "source": [
    "splits = int(len(df)/1100)\n",
    "\n",
    "X_real = df.loc[:,'f1':'f20']\n",
    "y_real = np.array(df.REDSHIFT_SPEC)\n",
    "\n",
    "kf_real = KFold(n_splits = splits)\n",
    "X_true_test = []\n",
    "X_to_train = []\n",
    "y_true_test = []\n",
    "y_to_train = []\n",
    "for train_index_real, test_index_real in kf_real.split(X_real):\n",
    "    print(\"X_true_test:\", train_index_real, \"X_to_train:\", test_index_real)\n",
    "    X_true_test.append(X_real.iloc[train_index_real])\n",
    "    X_to_train.append(X_real.iloc[test_index_real])\n",
    "    y_true_test.append(y_real[train_index_real])\n",
    "    y_to_train.append(y_real[test_index_real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 00th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 01th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 02th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 03th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 04th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 10th model\n",
      "[10:20:57] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 11th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 12th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 13th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 14th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 20th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 21th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 22th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 23th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 24th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 30th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 31th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 32th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 33th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 34th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 40th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 41th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 42th model\n",
      "[10:20:58] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 43th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 44th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 50th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 51th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 52th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 53th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 54th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 60th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 61th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 62th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 63th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 64th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 70th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 71th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 72th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 73th model\n",
      "[10:20:59] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 74th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 80th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 81th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 82th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 83th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 84th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 90th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 91th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 92th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 93th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 94th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 100th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 101th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 102th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 103th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 104th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 110th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 111th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 112th model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 113th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 114th model\n",
      "[10:21:00] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 120th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 121th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 122th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 123th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 124th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 130th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 131th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 132th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 133th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 134th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 140th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 141th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 142th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 143th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 144th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 150th model\n",
      "[10:21:01] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 151th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 152th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 153th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 154th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 160th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 161th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 162th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 163th model\n",
      "[10:21:02] WARNING: /workspace/src/objective/regression_obj.cu:167: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Fitting 164th model\n"
     ]
    }
   ],
   "source": [
    "preds_arr = []\n",
    "rmse_arr = []\n",
    "matrices_arr = []\n",
    "true_preds = []\n",
    "true_rms = []\n",
    "models = []\n",
    "\n",
    "for i in range(len(X_true_test)):\n",
    "    X_ = X_to_train[i]\n",
    "    y_ = y_to_train[i]\n",
    "    data_dmatrix = xgb.DMatrix(data=X_,label=y_)\n",
    "    kf = KFold(n_splits = 5)\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_):\n",
    "        X_train.append(X_.iloc[train_index])\n",
    "        X_test.append(X_.iloc[test_index])\n",
    "        y_train.append(y_[train_index])\n",
    "        y_test.append(y_[test_index])\n",
    "    \n",
    "    for j in range(len(X_train)):\n",
    "        xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "        xg_reg.fit(X_train[j],y_train[j])\n",
    "        print(\"Fitting \" + str(i) + str(j) + 'th model' )\n",
    "        \n",
    "        preds_arr.append(xg_reg.predict(X_test[j]))\n",
    "        rmse_arr.append(np.sqrt(mean_squared_error(y_test[j], preds_arr[-1])))\n",
    "        matrices_arr.append(np.round((abs(y_test[j]-preds_arr[-1])/y_test[j])*100))\n",
    "        \n",
    "        true_preds.append(xg_reg.predict(X_true_test[i]))\n",
    "        true_rms.append(np.sqrt(mean_squared_error(y_true_test[i], true_preds[-1])))\n",
    "        \n",
    "        models.append(xg_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21540375165857148,\n",
       " 0.21844376933435042,\n",
       " 0.21581567093282203,\n",
       " 0.21638661889471839,\n",
       " 0.21607320424894091,\n",
       " 0.22227557306057624,\n",
       " 0.22245018602421104,\n",
       " 0.22251334858521027,\n",
       " 0.21996905527344163,\n",
       " 0.2220629780560419,\n",
       " 0.2148842188295587,\n",
       " 0.2166000626974592,\n",
       " 0.21446604281648082,\n",
       " 0.21575687494009063,\n",
       " 0.21477071106686216,\n",
       " 0.21870993787529003,\n",
       " 0.21541921385176294,\n",
       " 0.215764884279458,\n",
       " 0.2160564169660949,\n",
       " 0.21779764804613383,\n",
       " 0.21623119962381038,\n",
       " 0.21568975215507422,\n",
       " 0.21597126934082572,\n",
       " 0.21576521057843642,\n",
       " 0.2145453465026029,\n",
       " 0.21329356093403193,\n",
       " 0.21177491083620437,\n",
       " 0.21489100579289433,\n",
       " 0.21427782483172023,\n",
       " 0.21260646005767722,\n",
       " 0.21412281496344057,\n",
       " 0.21551466009515974,\n",
       " 0.21635716305379438,\n",
       " 0.21542698183957362,\n",
       " 0.21716552238098383,\n",
       " 0.2175570297879746,\n",
       " 0.21872423074723296,\n",
       " 0.21864931233891458,\n",
       " 0.2192945769679698,\n",
       " 0.21827983897457814,\n",
       " 0.21641350057071332,\n",
       " 0.21870766587076265,\n",
       " 0.2173263148889989,\n",
       " 0.2175084417104568,\n",
       " 0.21636618873906568,\n",
       " 0.21582120316982487,\n",
       " 0.21849430223710073,\n",
       " 0.21853633513544662,\n",
       " 0.2171797751545982,\n",
       " 0.2156194851482254,\n",
       " 0.21617372511117824,\n",
       " 0.21851555593803285,\n",
       " 0.21835468640524222,\n",
       " 0.21749510235049663,\n",
       " 0.2169680354277919,\n",
       " 0.21698489154455247,\n",
       " 0.21844988370499724,\n",
       " 0.21618441436804217,\n",
       " 0.2162570444469526,\n",
       " 0.21898403279622586,\n",
       " 0.21530154600668952,\n",
       " 0.21649237648894457,\n",
       " 0.21721585327750212,\n",
       " 0.21612656389272358,\n",
       " 0.21608537984124462,\n",
       " 0.2172644473467008,\n",
       " 0.2171509514266551,\n",
       " 0.21587231693887718,\n",
       " 0.21812492362063546,\n",
       " 0.21736353988888038,\n",
       " 0.21821830424071284,\n",
       " 0.2187926375846948,\n",
       " 0.2191604597763509,\n",
       " 0.21716327652388925,\n",
       " 0.2187664884573367,\n",
       " 0.2179330698362561,\n",
       " 0.21647211802080735,\n",
       " 0.21676138619044677,\n",
       " 0.21641874526513458,\n",
       " 0.21551166567427385,\n",
       " 0.21616345670165804,\n",
       " 0.2185906828313339,\n",
       " 0.21661543275414574,\n",
       " 0.21650052477186663,\n",
       " 0.21834168510725577]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None),\n",
       " XGBRegressor(alpha=10, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='reg:linear', random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x['target'] = y_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SN853870</th>\n",
       "      <td>-629.395000</td>\n",
       "      <td>303.270839</td>\n",
       "      <td>12.595323</td>\n",
       "      <td>33.698785</td>\n",
       "      <td>61.524145</td>\n",
       "      <td>107.912514</td>\n",
       "      <td>-16.591236</td>\n",
       "      <td>78.319608</td>\n",
       "      <td>54.015820</td>\n",
       "      <td>-25.883775</td>\n",
       "      <td>...</td>\n",
       "      <td>18.025200</td>\n",
       "      <td>23.240546</td>\n",
       "      <td>45.436183</td>\n",
       "      <td>-10.717777</td>\n",
       "      <td>51.434519</td>\n",
       "      <td>7.823082</td>\n",
       "      <td>14.069987</td>\n",
       "      <td>13.366617</td>\n",
       "      <td>18.941023</td>\n",
       "      <td>0.78647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN853902</th>\n",
       "      <td>-403.577648</td>\n",
       "      <td>192.270572</td>\n",
       "      <td>155.156949</td>\n",
       "      <td>28.503750</td>\n",
       "      <td>48.944647</td>\n",
       "      <td>47.081357</td>\n",
       "      <td>43.389724</td>\n",
       "      <td>32.283089</td>\n",
       "      <td>46.477502</td>\n",
       "      <td>-26.778500</td>\n",
       "      <td>...</td>\n",
       "      <td>15.797907</td>\n",
       "      <td>0.430205</td>\n",
       "      <td>-0.923832</td>\n",
       "      <td>-22.369607</td>\n",
       "      <td>-30.614164</td>\n",
       "      <td>-44.732063</td>\n",
       "      <td>-0.913544</td>\n",
       "      <td>11.317149</td>\n",
       "      <td>-5.057367</td>\n",
       "      <td>0.57723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN853969</th>\n",
       "      <td>-467.981212</td>\n",
       "      <td>347.719269</td>\n",
       "      <td>55.226117</td>\n",
       "      <td>-44.268730</td>\n",
       "      <td>187.833934</td>\n",
       "      <td>77.768725</td>\n",
       "      <td>-70.415631</td>\n",
       "      <td>44.665149</td>\n",
       "      <td>68.788016</td>\n",
       "      <td>-81.759981</td>\n",
       "      <td>...</td>\n",
       "      <td>26.117386</td>\n",
       "      <td>30.663687</td>\n",
       "      <td>79.998134</td>\n",
       "      <td>3.568942</td>\n",
       "      <td>47.505044</td>\n",
       "      <td>20.833676</td>\n",
       "      <td>-16.535656</td>\n",
       "      <td>10.688689</td>\n",
       "      <td>1.569014</td>\n",
       "      <td>0.82993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN853988</th>\n",
       "      <td>206.697561</td>\n",
       "      <td>-922.440812</td>\n",
       "      <td>-687.318818</td>\n",
       "      <td>347.743523</td>\n",
       "      <td>374.290916</td>\n",
       "      <td>60.136555</td>\n",
       "      <td>-39.396776</td>\n",
       "      <td>-205.215301</td>\n",
       "      <td>131.837778</td>\n",
       "      <td>40.200574</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.061148</td>\n",
       "      <td>-26.281115</td>\n",
       "      <td>-115.586944</td>\n",
       "      <td>239.899460</td>\n",
       "      <td>-36.647179</td>\n",
       "      <td>-140.957871</td>\n",
       "      <td>83.598433</td>\n",
       "      <td>187.608737</td>\n",
       "      <td>51.442211</td>\n",
       "      <td>0.53846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN889448</th>\n",
       "      <td>-651.160018</td>\n",
       "      <td>125.051448</td>\n",
       "      <td>-144.373569</td>\n",
       "      <td>99.733687</td>\n",
       "      <td>24.222243</td>\n",
       "      <td>87.587307</td>\n",
       "      <td>98.619099</td>\n",
       "      <td>75.010385</td>\n",
       "      <td>50.674811</td>\n",
       "      <td>-42.103153</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.616121</td>\n",
       "      <td>-21.721253</td>\n",
       "      <td>-16.540688</td>\n",
       "      <td>-92.363507</td>\n",
       "      <td>21.027210</td>\n",
       "      <td>47.196277</td>\n",
       "      <td>-18.950516</td>\n",
       "      <td>-40.478649</td>\n",
       "      <td>-27.035689</td>\n",
       "      <td>0.93669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN889502</th>\n",
       "      <td>-549.305606</td>\n",
       "      <td>363.176014</td>\n",
       "      <td>-48.513350</td>\n",
       "      <td>24.329160</td>\n",
       "      <td>5.761858</td>\n",
       "      <td>122.775215</td>\n",
       "      <td>-6.807005</td>\n",
       "      <td>68.983099</td>\n",
       "      <td>13.455541</td>\n",
       "      <td>-14.603582</td>\n",
       "      <td>...</td>\n",
       "      <td>15.827956</td>\n",
       "      <td>5.953496</td>\n",
       "      <td>20.170417</td>\n",
       "      <td>3.460617</td>\n",
       "      <td>-6.009495</td>\n",
       "      <td>-8.892416</td>\n",
       "      <td>-1.746711</td>\n",
       "      <td>-15.610291</td>\n",
       "      <td>-4.720978</td>\n",
       "      <td>0.44127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN889601</th>\n",
       "      <td>-398.956615</td>\n",
       "      <td>167.277835</td>\n",
       "      <td>-42.545553</td>\n",
       "      <td>7.442509</td>\n",
       "      <td>8.130408</td>\n",
       "      <td>20.720640</td>\n",
       "      <td>35.182567</td>\n",
       "      <td>44.023975</td>\n",
       "      <td>-21.817749</td>\n",
       "      <td>-3.855144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394047</td>\n",
       "      <td>3.677997</td>\n",
       "      <td>15.461803</td>\n",
       "      <td>6.416959</td>\n",
       "      <td>-7.194665</td>\n",
       "      <td>29.776331</td>\n",
       "      <td>8.357631</td>\n",
       "      <td>36.651304</td>\n",
       "      <td>19.108292</td>\n",
       "      <td>0.50331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SN889642</th>\n",
       "      <td>-295.898559</td>\n",
       "      <td>297.202399</td>\n",
       "      <td>-34.125555</td>\n",
       "      <td>13.815035</td>\n",
       "      <td>35.849094</td>\n",
       "      <td>58.891053</td>\n",
       "      <td>-41.956630</td>\n",
       "      <td>1.834201</td>\n",
       "      <td>-111.401344</td>\n",
       "      <td>-28.097156</td>\n",
       "      <td>...</td>\n",
       "      <td>5.665985</td>\n",
       "      <td>4.035805</td>\n",
       "      <td>20.086595</td>\n",
       "      <td>49.950037</td>\n",
       "      <td>-31.388733</td>\n",
       "      <td>7.583459</td>\n",
       "      <td>9.997335</td>\n",
       "      <td>9.807498</td>\n",
       "      <td>-17.450555</td>\n",
       "      <td>0.91502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  f1          f2          f3          f4          f5  \\\n",
       "ID                                                                     \n",
       "SN853870 -629.395000  303.270839   12.595323   33.698785   61.524145   \n",
       "SN853902 -403.577648  192.270572  155.156949   28.503750   48.944647   \n",
       "SN853969 -467.981212  347.719269   55.226117  -44.268730  187.833934   \n",
       "SN853988  206.697561 -922.440812 -687.318818  347.743523  374.290916   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "SN889448 -651.160018  125.051448 -144.373569   99.733687   24.222243   \n",
       "SN889502 -549.305606  363.176014  -48.513350   24.329160    5.761858   \n",
       "SN889601 -398.956615  167.277835  -42.545553    7.442509    8.130408   \n",
       "SN889642 -295.898559  297.202399  -34.125555   13.815035   35.849094   \n",
       "\n",
       "                  f6         f7          f8          f9        f10  ...  \\\n",
       "ID                                                                  ...   \n",
       "SN853870  107.912514 -16.591236   78.319608   54.015820 -25.883775  ...   \n",
       "SN853902   47.081357  43.389724   32.283089   46.477502 -26.778500  ...   \n",
       "SN853969   77.768725 -70.415631   44.665149   68.788016 -81.759981  ...   \n",
       "SN853988   60.136555 -39.396776 -205.215301  131.837778  40.200574  ...   \n",
       "...              ...        ...         ...         ...        ...  ...   \n",
       "SN889448   87.587307  98.619099   75.010385   50.674811 -42.103153  ...   \n",
       "SN889502  122.775215  -6.807005   68.983099   13.455541 -14.603582  ...   \n",
       "SN889601   20.720640  35.182567   44.023975  -21.817749  -3.855144  ...   \n",
       "SN889642   58.891053 -41.956630    1.834201 -111.401344 -28.097156  ...   \n",
       "\n",
       "                f12        f13         f14         f15        f16         f17  \\\n",
       "ID                                                                              \n",
       "SN853870  18.025200  23.240546   45.436183  -10.717777  51.434519    7.823082   \n",
       "SN853902  15.797907   0.430205   -0.923832  -22.369607 -30.614164  -44.732063   \n",
       "SN853969  26.117386  30.663687   79.998134    3.568942  47.505044   20.833676   \n",
       "SN853988 -18.061148 -26.281115 -115.586944  239.899460 -36.647179 -140.957871   \n",
       "...             ...        ...         ...         ...        ...         ...   \n",
       "SN889448 -12.616121 -21.721253  -16.540688  -92.363507  21.027210   47.196277   \n",
       "SN889502  15.827956   5.953496   20.170417    3.460617  -6.009495   -8.892416   \n",
       "SN889601   0.394047   3.677997   15.461803    6.416959  -7.194665   29.776331   \n",
       "SN889642   5.665985   4.035805   20.086595   49.950037 -31.388733    7.583459   \n",
       "\n",
       "                f18         f19        f20   target  \n",
       "ID                                                   \n",
       "SN853870  14.069987   13.366617  18.941023  0.78647  \n",
       "SN853902  -0.913544   11.317149  -5.057367  0.57723  \n",
       "SN853969 -16.535656   10.688689   1.569014  0.82993  \n",
       "SN853988  83.598433  187.608737  51.442211  0.53846  \n",
       "...             ...         ...        ...      ...  \n",
       "SN889448 -18.950516  -40.478649 -27.035689  0.93669  \n",
       "SN889502  -1.746711  -15.610291  -4.720978  0.44127  \n",
       "SN889601   8.357631   36.651304  19.108292  0.50331  \n",
       "SN889642   9.997335    9.807498 -17.450555  0.91502  \n",
       "\n",
       "[890 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(x)\n",
    "\n",
    "col = x.columns\n",
    "new_data = pd.DataFrame(data_scaled, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f12</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.299377</td>\n",
       "      <td>0.246067</td>\n",
       "      <td>0.046648</td>\n",
       "      <td>0.156361</td>\n",
       "      <td>0.167691</td>\n",
       "      <td>0.369178</td>\n",
       "      <td>-0.036740</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.119793</td>\n",
       "      <td>-0.252697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217492</td>\n",
       "      <td>0.108364</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>-0.067897</td>\n",
       "      <td>0.477564</td>\n",
       "      <td>0.084738</td>\n",
       "      <td>0.053375</td>\n",
       "      <td>0.210261</td>\n",
       "      <td>0.242915</td>\n",
       "      <td>0.479799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.183171</td>\n",
       "      <td>0.168660</td>\n",
       "      <td>0.233068</td>\n",
       "      <td>0.136186</td>\n",
       "      <td>0.132883</td>\n",
       "      <td>0.177529</td>\n",
       "      <td>0.132998</td>\n",
       "      <td>0.112427</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>-0.259776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194442</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>-0.165903</td>\n",
       "      <td>-0.393953</td>\n",
       "      <td>-0.387040</td>\n",
       "      <td>-0.053500</td>\n",
       "      <td>0.182654</td>\n",
       "      <td>-0.092556</td>\n",
       "      <td>-0.431698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.216313</td>\n",
       "      <td>0.277063</td>\n",
       "      <td>0.102394</td>\n",
       "      <td>-0.146434</td>\n",
       "      <td>0.517193</td>\n",
       "      <td>0.274210</td>\n",
       "      <td>-0.189055</td>\n",
       "      <td>0.150992</td>\n",
       "      <td>0.158201</td>\n",
       "      <td>-0.694769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301236</td>\n",
       "      <td>0.149652</td>\n",
       "      <td>0.573201</td>\n",
       "      <td>0.052272</td>\n",
       "      <td>0.435826</td>\n",
       "      <td>0.201531</td>\n",
       "      <td>-0.164930</td>\n",
       "      <td>0.174188</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.669120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130880</td>\n",
       "      <td>-0.608692</td>\n",
       "      <td>-0.868587</td>\n",
       "      <td>1.375988</td>\n",
       "      <td>1.033124</td>\n",
       "      <td>0.218659</td>\n",
       "      <td>-0.101276</td>\n",
       "      <td>-0.627280</td>\n",
       "      <td>0.322133</td>\n",
       "      <td>0.270137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155957</td>\n",
       "      <td>-0.167075</td>\n",
       "      <td>-0.775138</td>\n",
       "      <td>2.040096</td>\n",
       "      <td>-0.458035</td>\n",
       "      <td>-1.250840</td>\n",
       "      <td>0.549311</td>\n",
       "      <td>2.557359</td>\n",
       "      <td>0.697245</td>\n",
       "      <td>-0.600589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-0.310578</td>\n",
       "      <td>0.121784</td>\n",
       "      <td>-0.158610</td>\n",
       "      <td>0.412815</td>\n",
       "      <td>0.064476</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>0.289290</td>\n",
       "      <td>0.245504</td>\n",
       "      <td>0.111106</td>\n",
       "      <td>-0.381019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099608</td>\n",
       "      <td>-0.141713</td>\n",
       "      <td>-0.092326</td>\n",
       "      <td>-0.754636</td>\n",
       "      <td>0.154579</td>\n",
       "      <td>0.438183</td>\n",
       "      <td>-0.182155</td>\n",
       "      <td>-0.515053</td>\n",
       "      <td>-0.399789</td>\n",
       "      <td>1.134191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-0.258163</td>\n",
       "      <td>0.287842</td>\n",
       "      <td>-0.033260</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.416003</td>\n",
       "      <td>-0.009052</td>\n",
       "      <td>0.226732</td>\n",
       "      <td>0.014334</td>\n",
       "      <td>-0.163453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194753</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.160756</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>-0.132603</td>\n",
       "      <td>-0.065314</td>\n",
       "      <td>-0.059443</td>\n",
       "      <td>-0.180068</td>\n",
       "      <td>-0.087854</td>\n",
       "      <td>-1.023971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>-0.180793</td>\n",
       "      <td>0.151231</td>\n",
       "      <td>-0.025456</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>0.019949</td>\n",
       "      <td>0.094479</td>\n",
       "      <td>0.109773</td>\n",
       "      <td>0.148995</td>\n",
       "      <td>-0.077377</td>\n",
       "      <td>-0.078415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035031</td>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.128295</td>\n",
       "      <td>0.076227</td>\n",
       "      <td>-0.145192</td>\n",
       "      <td>0.281808</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.523913</td>\n",
       "      <td>0.245253</td>\n",
       "      <td>-0.753711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-0.127759</td>\n",
       "      <td>0.241835</td>\n",
       "      <td>-0.014446</td>\n",
       "      <td>0.079140</td>\n",
       "      <td>0.096647</td>\n",
       "      <td>0.214735</td>\n",
       "      <td>-0.108520</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>-0.310298</td>\n",
       "      <td>-0.270209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089589</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.160178</td>\n",
       "      <td>0.442392</td>\n",
       "      <td>-0.402180</td>\n",
       "      <td>0.082587</td>\n",
       "      <td>0.024326</td>\n",
       "      <td>0.162318</td>\n",
       "      <td>-0.265799</td>\n",
       "      <td>1.039792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0   -0.299377  0.246067  0.046648  0.156361  0.167691  0.369178 -0.036740   \n",
       "1   -0.183171  0.168660  0.233068  0.136186  0.132883  0.177529  0.132998   \n",
       "2   -0.216313  0.277063  0.102394 -0.146434  0.517193  0.274210 -0.189055   \n",
       "3    0.130880 -0.608692 -0.868587  1.375988  1.033124  0.218659 -0.101276   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "886 -0.310578  0.121784 -0.158610  0.412815  0.064476  0.305143  0.289290   \n",
       "887 -0.258163  0.287842 -0.033260  0.119973  0.013395  0.416003 -0.009052   \n",
       "888 -0.180793  0.151231 -0.025456  0.054392  0.019949  0.094479  0.109773   \n",
       "889 -0.127759  0.241835 -0.014446  0.079140  0.096647  0.214735 -0.108520   \n",
       "\n",
       "           f8        f9       f10  ...       f12       f13       f14  \\\n",
       "0    0.255811  0.119793 -0.252697  ...  0.217492  0.108364  0.334935   \n",
       "1    0.112427  0.100193 -0.259776  ...  0.194442 -0.018507  0.015335   \n",
       "2    0.150992  0.158201 -0.694769  ...  0.301236  0.149652  0.573201   \n",
       "3   -0.627280  0.322133  0.270137  ... -0.155957 -0.167075 -0.775138   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "886  0.245504  0.111106 -0.381019  ... -0.099608 -0.141713 -0.092326   \n",
       "887  0.226732  0.014334 -0.163453  ...  0.194753  0.012214  0.160756   \n",
       "888  0.148995 -0.077377 -0.078415  ...  0.035031 -0.000442  0.128295   \n",
       "889  0.017591 -0.310298 -0.270209  ...  0.089589  0.001548  0.160178   \n",
       "\n",
       "          f15       f16       f17       f18       f19       f20    target  \n",
       "0   -0.067897  0.477564  0.084738  0.053375  0.210261  0.242915  0.479799  \n",
       "1   -0.165903 -0.393953 -0.387040 -0.053500  0.182654 -0.092556 -0.431698  \n",
       "2    0.052272  0.435826  0.201531 -0.164930  0.174188  0.000073  0.669120  \n",
       "3    2.040096 -0.458035 -1.250840  0.549311  2.557359  0.697245 -0.600589  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "886 -0.754636  0.154579  0.438183 -0.182155 -0.515053 -0.399789  1.134191  \n",
       "887  0.051360 -0.132603 -0.065314 -0.059443 -0.180068 -0.087854 -1.023971  \n",
       "888  0.076227 -0.145192  0.281808  0.012630  0.523913  0.245253 -0.753711  \n",
       "889  0.442392 -0.402180  0.082587  0.024326  0.162318 -0.265799  1.039792  \n",
       "\n",
       "[890 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1 \n",
    "interations = 1000 # número de interações\n",
    "\n",
    "theta = np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Body Weight', 'Brain Weight']\n",
    "new_data = pd.DataFrame(data_scaled, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "true_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(df.REDSHIFT_SPEC, bins=100, color=\"g\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(true_rms, bins=85, color=\"g\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21177491083620437"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8259746290653105"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array(true_rms).max() - np.array(true_rms).min())/np.array(true_rms).max())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
